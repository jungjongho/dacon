{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "train = pd.read_csv('/content/train.csv')\n",
    "test = pd.read_csv('/content/test.csv')\n",
    "d_code=pd.read_csv('/content/속성_D_코드.csv',index_col=0).T.to_dict()\n",
    "h_code=pd.read_csv('/content/속성_H_코드.csv',index_col=0).T.to_dict()\n",
    "l_code=pd.read_csv('/content/속성_L_코드.csv',index_col=0).T.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 데이터중에서 날짜와 각 개인번호의 경우 명목형에 너무 많은 분류가있어서 굳이 의미없다는 생각에 제거하였고\n",
    "\n",
    "person_prefer_f와 person_prefer_g의 경우 모두 같은 값을 가지고있어서 데이터에서 제외하였습니다.(-_-님의 코드 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터중 일부 변수 제거\n",
    "\n",
    "train = train.drop(['id', 'contents_open_dt','person_rn', 'contents_rn',\n",
    "# 'person_prefer_d_1','person_prefer_d_2','person_prefer_d_3',\n",
    "# 'contents_attribute_d','person_prefer_h_1','person_prefer_h_2','person_prefer_h_3','contents_attribute_h','contents_attribute_l',\n",
    "'person_prefer_f','person_prefer_g'], axis=1) \n",
    "\n",
    "\n",
    "test = test.drop(['id', 'contents_open_dt','person_rn', 'contents_rn',\n",
    "# 'person_prefer_d_1','person_prefer_d_2','person_prefer_d_3',\n",
    "# 'contents_attribute_d','person_prefer_h_1','person_prefer_h_2','person_prefer_h_3','contents_attribute_h','contents_attribute_l',\n",
    "'person_prefer_f','person_prefer_g'], axis=1)\n",
    "\n",
    "# print(train.head())\n",
    "train['d_l_match_yn']=train['d_l_match_yn'].replace([True,False],[1,0])\n",
    "train['d_m_match_yn']=train['d_m_match_yn'].replace([True,False],[1,0])\n",
    "train['d_s_match_yn']=train['d_s_match_yn'].replace([True,False],[1,0])\n",
    "train['h_l_match_yn']=train['h_l_match_yn'].replace([True,False],[1,0])\n",
    "train['h_m_match_yn']=train['h_m_match_yn'].replace([True,False],[1,0])\n",
    "train['h_s_match_yn']=train['h_s_match_yn'].replace([True,False],[1,0])\n",
    "\n",
    "test['d_l_match_yn']=test['d_l_match_yn'].replace([True,False],[1,0])\n",
    "test['d_m_match_yn']=test['d_m_match_yn'].replace([True,False],[1,0])\n",
    "test['d_s_match_yn']=test['d_s_match_yn'].replace([True,False],[1,0])\n",
    "test['h_l_match_yn']=test['h_l_match_yn'].replace([True,False],[1,0])\n",
    "test['h_m_match_yn']=test['h_m_match_yn'].replace([True,False],[1,0])\n",
    "test['h_s_match_yn']=test['h_s_match_yn'].replace([True,False],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 colab에서 gpu를 가져다 썼는데 정말 더 빠른지는 아직 체감하지 못했습니다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 상태 확인과 기존에 너무 숫자가 큰탓에 모델이 안돌아가는것인가? 했지만\n",
    "\n",
    "아니라는 사실을 깨닫고 다시 원상태로 해놨습니다. 그런데 변수의 숫자 크기에따라 모델의 성능이 조금 차이난다는 사실을 경험적으로 알수있었습니다. 전부 0과 10사이로 맞추는게 좀더 모델성능이 높게 나왔습니다. 물론 100과 10이 같은 변수가 된다는것을 감안 해서도요.\n",
    "\n",
    "이번이 처음인지라 이번케이스에서만 그런건지 아님 다른케이스에서도 그런건지는 잘 모르겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader의사용\n",
    "\n",
    "x = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]\n",
    "\n",
    "x= x.to_numpy()\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "# x=np.where(x > 1000, x/1000, x)\n",
    "# x=np.where(x > 100, x/100, x)\n",
    "# x=np.where(x > 10, x/10, x)\n",
    "# x=x/10\n",
    "x=torch.Tensor(x)\n",
    "\n",
    "print(x.size())\n",
    "print(x[0][1])\n",
    "y=torch.Tensor(y)\n",
    "\n",
    "print(x)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "dataset_train = TensorDataset(x_train, y_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "dataset_valid = TensorDataset(x_valid, y_valid)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "x_test=test.iloc[:]\n",
    "x_test=x_test.to_numpy()\n",
    "# x_test=np.where(x_test > 1000, x_test/1000, x_test)\n",
    "# x_test=np.where(x_test > 100, x_test/100, x_test)\n",
    "# x_test=np.where(x_test > 10, x_test/10, x_test)\n",
    "# x_test=x_test/10\n",
    "print(x_test.shape)\n",
    "x_test=torch.FloatTensor(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticeRegression모델입니다.\n",
    "데이터가 워낙 많은지라 깊을수록 좋다고 판단해서 9층까지 넣었는데 5~9층 모두 비슷한 성능을 보여주었습니다.\n",
    "\n",
    "깊게넣느라 LeaKReLU를 사용하고 마지막에 sigmoid를 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        # self.linear = nn.Sequential(\n",
    "        self.linear1=nn.Linear(28,16)\n",
    "        self.batch_normal1=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear2=nn.Linear(16, 16)\n",
    "        self.batch_normal2=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear3=nn.Linear(16, 16)\n",
    "        self.batch_normal3=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear4=nn.Linear(16, 16)\n",
    "        self.batch_normal4=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear5=nn.Linear(16, 16)\n",
    "        self.batch_normal5=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear6=nn.Linear(16, 16)\n",
    "        self.batch_normal6=nn.BatchNorm1d(16)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.linear7=nn.Linear(16, 1)\n",
    "        self.batch_normal7=nn.BatchNorm1d(1)\n",
    "        self.LeakRelu=nn.LeakyReLU()\n",
    "\n",
    "        self.sigmoid=nn.Sigmoid()    \n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear4.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear5.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear6.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.linear7.weight)\n",
    "        # )        \n",
    "#  self.linear2,self.batch_normal2, self.LeakRelu, \n",
    "        self.model=nn.Sequential(self.linear1, self.batch_normal1, self.LeakRelu,\n",
    "                                 self.linear2,self.batch_normal2, self.LeakRelu, \n",
    "                                 self.linear3,self.batch_normal3,self.LeakRelu,\n",
    "                                 self.linear4, self.batch_normal4,self.LeakRelu,\n",
    "                                 self.linear5, self.batch_normal5,self.LeakRelu,\n",
    "                                 self.linear6, self.batch_normal6,self.LeakRelu,\n",
    "                                 self.linear7, self.batch_normal7,self.LeakRelu,\n",
    "                                 self.sigmoid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model1=LogisticRegression().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimzer는 Adam을 사용했습니다. 일단 가장 많이들 사용한다고 하더군요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1=nn.CrossEntropyLoss().to(device)\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "print(model1.parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 을 돌리는 코드입니다.\n",
    "\n",
    "밑에서 시각화를 해보려했고 가장 높은 epoch을 선택하기위해 torch.save()함수를 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 50\n",
    "accuracy_list_train=[]\n",
    "accuracy_list_valid=[]\n",
    "f1_list_train=[]\n",
    "f1_list_valid=[]\n",
    "accuracy_mean=0\n",
    "f1_mean=0\n",
    "\n",
    "# x_valid, y_valid=dataset_valid\n",
    "\n",
    "x_valid=x_valid.to(device)\n",
    "y_valid=y_valid.to(device)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader_train):\n",
    "\n",
    "        x_train, y_train = samples\n",
    "\n",
    "        x_train=x_train.to(device)\n",
    "        y_train=y_train.to(device)\n",
    "\n",
    "\n",
    "        # H(x) 계산\n",
    "        hypothesis = model1(x_train)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # cost 계산\n",
    "        # print(y_train.size())\n",
    "        hypothesis=hypothesis.squeeze()\n",
    "        # print(hypothesis.size())\n",
    "        # print(hypothesis)\n",
    "        # print(y_train)\n",
    "        cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "        # cost로 H(x) 개선\n",
    "        optimizer1.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        bigo=torch.FloatTensor([0.5]).to(device)\n",
    "\n",
    "        prediction = hypothesis >= bigo # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        accuracy_mean= accuracy+accuracy_mean\n",
    "        f1 = f1_score(y_train.cpu(), prediction.float().cpu())\n",
    "        f1_mean=f1 + f1_mean\n",
    "\n",
    "        # 20번마다 로그 출력\n",
    "        if epoch % 10 == 0:\n",
    "          if batch_idx %1000 == 0:\n",
    "              prediction = hypothesis >= bigo # 예측값이 0.5를 넘으면 True로 간주\n",
    "              correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "              accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "              f1 = f1_score(y_train.cpu(), prediction.float().cpu())\n",
    "              print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f} Accuracy {:2.2f}%  f1 score : {:2.6f}'.format( # 각 에포크마다 정확도를 출력\n",
    "                  epoch, nb_epochs, batch_idx+1, len(dataloader_train), cost.item(), accuracy * 100, f1\n",
    "              ))\n",
    "\n",
    "    accuracy_mean=accuracy_mean/len(dataloader_train)\n",
    "    accuracy_list_train.append(accuracy_mean)\n",
    "    f1_mean=f1_mean/len(dataloader_train)\n",
    "    f1_list_train.append(f1_mean)\n",
    "\n",
    "    valid_hypothesis = model1(x_valid)\n",
    "    valid_hypothesis=valid_hypothesis.squeeze()\n",
    "    valid_prediction = valid_hypothesis >= bigo # 예측값이 0.5를 넘으면 True로 간주\n",
    "    valid_correct_prediction = valid_prediction.float() == y_valid # 실제값과 일치하는 경우만 True로 간주\n",
    "    valid_accuracy = valid_correct_prediction.sum().item() / len(valid_correct_prediction) # 정확도를 계산\n",
    "    # print(valid_hypothesis)\n",
    "    # print(valid_prediction)\n",
    "    \n",
    "    # print(valid_accuracy)\n",
    "    # print(len(valid_correct_prediction))\n",
    "    # print(valid_correct_prediction.sum().item())\n",
    "    valid_f1 = f1_score(y_valid.cpu(), valid_prediction.float().cpu())\n",
    "\n",
    "    accuracy_list_valid.append(valid_accuracy)\n",
    "    f1_list_valid.append(valid_f1)\n",
    "    torch.save(model1.state_dict(), f'{epoch:04d}.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 epoch당 정확도와 f1_score을 시각화 한것입니다. 각각을 담은 리스트는 바로 위의 코드에 같이 적혀있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "t=range(0,nb_epochs+1)\n",
    "print(len(accuracy_list_train))\n",
    "print(len(accuracy_list_valid))\n",
    "\n",
    "plt.plot(t,accuracy_list_train,'r--',t,accuracy_list_valid,'g-')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_list_train)\n",
    "print(accuracy_list_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t,f1_list_train,'r--',t,f1_list_valid,'g-')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f1_list_train)\n",
    "print(f1_list_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 제출 코드입니다. 여기서 가장 성능이 좋았다고 판단되는 epoch의 모델을 가져와서 결과를 냅니다.\n",
    "\n",
    "train(빨간줄) 보다 valid(녹색)줄의 성능이 더 좋은것을 가져와야 할것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.read_csv('/content/sample_submission.csv')\n",
    "\n",
    "model2=LogisticRegression()\n",
    "model2.load_state_dict(torch.load('/content/0010.pt'))\n",
    "\n",
    "x_test=x_test.to(device)\n",
    "hypothesis=model2(x_test)\n",
    "print(hypothesis)\n",
    "prediction = hypothesis >= torch.FloatTensor([0.5]).to(device) # 예측값이 0.5를 넘으면 True로 간주\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "prediction = torch.squeeze(prediction)\n",
    "prediction=prediction.cpu()\n",
    "prediction=np.array(prediction)\n",
    "prediction=pd.Series(prediction)\n",
    "\n",
    "prediction=prediction.replace([True,False],[1,0])\n",
    "\n",
    "result['target']=prediction\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델을 직접 만들어보고 싶었는데 이번기회에 간단하게나마 하나 만들어 볼수있어서 굉장히 좋은 기회였습니다.\n",
    "\n",
    "어떤식으로 해야 위의 성능이 좀더 좋아질수 있을까 여러 측면으로 고민해보고 다른 모델은 어떠할지 비교해봐야 겠습니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "711798a1253e42aea39410b452da8b3c7dc6309309029f9a45f64c032f4e4fab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('stockpredict': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
